{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "from LS_AMG_RAG.data_snythesis import prompt_utils\n",
    "import google.generativeai as palm\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "# chroma_client = chromadb.Client()\n",
    "chroma_client = chromadb.PersistentClient(path=\"./\")\n",
    "gemini = prompt_utils.Gemini()\n",
    "google_ef  = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=os.environ['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "# for idx, file_name in enumerate(os.listdir(\"../data/business_docs\")):\n",
    "#     with open(f\"../data/business_docs/{file_name}\", \"r\") as f:\n",
    "#         file_contents = f.read()\n",
    "#         documents.append(file_contents)\n",
    "#         metadata.append({\n",
    "#             \"type\": \"business document\",\n",
    "#         })\n",
    "#         ids.append(f\"business_doc_{idx}\")\n",
    "\n",
    "# add all files within the 'data/' directory to chromadb using os.walk\n",
    "for root, dirs, files in os.walk(\"../data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".md\"):\n",
    "            category = root.split('\\\\')[-1]\n",
    "            with open(os.path.join(root, file), \"r\") as f:\n",
    "                file_contents = f.read()\n",
    "                documents.append(file_contents)\n",
    "                metadata.append({\n",
    "                    \"type\": category,\n",
    "                })\n",
    "                ids.append(f\"{category}_{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n",
      "models/embedding-001\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in palm.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\", embedding_function=google_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadata,\n",
    "    ids=ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection.get()['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document retrieved: company_bylaws_About Instagram.md\n",
      "Retrieval time: 0.4795975685119629 seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The reference document you provided does not include any information about Instagram's board of directors. Therefore, I cannot answer this question."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini time: 2.6514804363250732 seconds\n",
      "Total time: 3.131078004837036 seconds\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Who are the members of Instagram's board of directors?\",\n",
    "]\n",
    "import time\n",
    "total_start_time = time.time()\n",
    "start_time = time.time()\n",
    "results = collection.query(\n",
    "    query_texts=queries,\n",
    "    n_results=3\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Document retrieved: {results['ids'][0][-1]}\")\n",
    "\n",
    "print(f\"Retrieval time: {end_time - start_time} seconds\")\n",
    "\n",
    "metaprompt = \"\"\"You are a helpful and informative bot that answers questions using text from the reference document included below. \\\n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "strike a friendly and converstional tone. \\\n",
    "Use your own knowledge base in addition to the information provided in the document to answer the question. \\\n",
    "Make relevant assumptions and use your best judgement to answer the question. \\\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "  ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "gemini_result = gemini.send_message(message=metaprompt.format(query=queries[0], relevant_passage=results['documents'][0][-1])).text\n",
    "end_time = time.time()\n",
    "total_end_time = time.time()\n",
    "display(Markdown(gemini_result))\n",
    "print(f\"Gemini time: {end_time - start_time} seconds\")\n",
    "print(f\"Total time: {total_end_time - total_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I apologize, but I cannot answer your question as the provided text does not contain any information about the Direct Messaging update or any challenges associated with it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query time: 2.1806864738464355 seconds\n"
     ]
    }
   ],
   "source": [
    "metaprompt = \"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone. \\\n",
    "  If the passage is irrelevant to the answer, you may ignore it.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "  ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "gemini_result = gemini.send_message(message=metaprompt.format(query=queries[0], relevant_passage=results['documents'][0][-1])).text\n",
    "end_time = time.time()\n",
    "display(Markdown(gemini_result))\n",
    "print(f\"Query time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
